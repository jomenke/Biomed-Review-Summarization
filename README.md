# Biomed-Review-Summarization
Data and code for aspect-based summarization of biomedical review articles.

We created our dataset, utilizing 4 article-summary pairings from different perspectives: abstract summary, layperson summary, implications for research summary, and implications for practice. This dataset contains 302 review articles published by the Cochrane Database of Systematic Reviews. These articles all include summaries of the 4 different perspectives and were downloaded through the PubMed Central Open Archives Initiative (PMC-OAI) as XML files. These XML files were then parsed to separate the 4 different summaries from the other article text. This dataset is split roughly into training (60%, n=194), validation (30%, n=84), test (10%, n=25) splits for system development. Test was split by year; any article published in 2024 was placed into the test set as instances without any sort of data leakage for a majority of evaluated LLM models (e.g., GPT-4 models have a knowledge cut-off of October 2023). The remaining articles were split randomly into training and validation sets. Data is made available through box (https://uofi.box.com/s/0o0zd8e9qs2l8o8cekx5rcjl9toz19j2).

Code is made available here. Hyperparameters include persona, reflection, evaluate_performance, base_model, temperature, max_content_length (max input length), and max_tokens (max output length). Evaluation metrcs include ROUGE-1-2-L, BertScore (https://arxiv.org/abs/1904.09675), SummaC-conv, SARI (https://aclanthology.org/Q16-1029/), Flesch-Kincaid Grade Level (FKGL), and Dale-Chall Readability Score (DCRS). This code can run 3 different experiments. Experiment 1 (persona and reflection are false) establishes an initial baseline using 4 manually crafted prompts. Experiment 2 (persona is true) generates a summary using a generated user-persona. Experiment 3 (persona and reflection are true) generates a summary using a generated user-persona, who then reflects, critiques, and edits the generated summary.
